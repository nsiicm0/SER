{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not spend too much time trying to get very tiny metrics improvement. Once you have a model with a correct predictive power, you should better spend time explaining your data cleaning & preparation pipeline as well as explanations & visualizations of the results.\n",
    "\n",
    "The goal is to see your fit with our company culture & engineering needs, spending 50h on an over-complicated approach will not give you bonus points compared to a simple, yet effective, to-the-point solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset you will be working with is called Emo-DB and can be found [here](http://emodb.bilderbar.info/index-1280.html).\n",
    "\n",
    "It is a database containing samples of emotional speech in German. It contains samples labeled with one of 7 different emotions: Anger, Boredom, Disgust, Fear, Happiness, Sadness and Neutral. \n",
    "\n",
    "Please download the full database and refer to the documentation to understand how the samples are labeled (see \"Additional information\")\n",
    "   \n",
    "The goal of this project is to develop a model which is able to **classify samples of emotional speech**. Feel free to use any available library you would need, but beware of re-using someone else's code without mentionning it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The end-goal is to deliver us a zip file containing:\n",
    "* This report filled with your approach, in the form of an **iPython Notebook**.\n",
    "* A **5-10 slides PDF file**, containing a technical presentation covering the important aspects of your work\n",
    "* A Dockerfile which defines a container for the project. The container should handle everything (download the data, run the code, etc...). When running the container it should expose the jupyter notebook on one port and expose a Flask API on another one. The Flask app contains two endpoints:\n",
    "  - One for training the model\n",
    "  - One for querying the last trained model with an audio file of our choice in the dataset\n",
    "* A README.md which should contain the commands to build and run the docker container, as well as how to perform the queries to the API. \n",
    "* Any necessary .py, .sh or other files needed to run your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "    AUTHOR: Niclas Simmler\n",
    "    DATE: April 22, 2021\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will need to do some basic setup. We will activate autoreload and make sure the src code is visible in jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config Application.log_level=\"DEBUG\"\n",
    "import os\n",
    "import sys\n",
    "\n",
    "PROJECT_BASE_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "DATA_BASE_PATH = os.path.join(PROJECT_BASE_PATH, 'data')\n",
    "SRC_BASE_PATH = os.path.join(PROJECT_BASE_PATH, 'src')\n",
    "sys.path.insert(0, SRC_BASE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load our required modules.\n",
    "\n",
    "We start of with our very own `ser` module. This one will hold all relevant functionalities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load some other common modules which we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation & Cleaning\n",
    "\n",
    "## Download\n",
    "\n",
    "We will first need to download the data if not already done so. In order to deal with all the logic, a wrapper class will be used, which allows for easy operation on the dataset.\n",
    "\n",
    "The code for the dataset wrapper can be found in `src/ser/dataset.py`. First, instantiate a dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-22 20:51:06,026 - ser.dataset - INFO - Creating Dataset Wrapper object.\n",
      "2021-04-22 20:51:06,027 - ser.dataset - INFO - > Base Path at \"/Users/nik/Code/visium/data\"\n",
      "2021-04-22 20:51:06,029 - ser.dataset - INFO - > Pristine Path at \"/Users/nik/Code/visium/data/pristine\"\n",
      "2021-04-22 20:51:06,030 - ser.dataset - INFO - > Working Path at \"/Users/nik/Code/visium/data/working\"\n",
      "2021-04-22 20:51:06,031 - ser.dataset - INFO - Make sure that the http://emodb.bilderbar.info/download/download.zip points to a ZIP file.\n"
     ]
    }
   ],
   "source": [
    "dataset = ser.Dataset(data_path=DATA_BASE_PATH, remote_url='http://emodb.bilderbar.info/download/download.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this line below if you want to clean the data directory\n",
    "#dataset.clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we download the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-22 20:52:55,749 - ser.dataset - INFO - Successfully downloaded file to /Users/nik/Code/visium/data/pristine/download.zip\n",
      "2021-04-22 20:52:55,750 - ser.dataset - INFO - Dataset downloaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return value of the download is `True`, thus, everything went fine. If we were to rerun this function, it would not download anything anymore. However, using the `force=True` argument, we can initiate the download again.\n",
    "\n",
    "Since it is a ZIP File, we will need to extract it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-22 20:53:32,451 - ser.dataset - INFO - Dataset extracted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extraction went well too. If we were to rerun this function, it would not extract anything anymore. However, using the `force=True` argument, we can initiate the extraction again.\n",
    "\n",
    "Now we need to parse the data. For this, let's have a look at the documentation (http://www.emodb.bilderbar.info/index-1280.html)\n",
    "\n",
    "In our data folder, we have multiple files and folders. Not all of them are relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wav', '.gitkeep', 'silb', 'erklaerung.txt', 'lablaut', 'erkennung.txt', 'labsilb']\n",
      "['16a02Lb.wav', '14a07Wc.wav', '10a07Ad.wav', '13a05Ea.wav', '14a05Wa.wav', '14a07Na.wav', '15a05Wa.wav', '16b10Wb.wav', '09a01Nb.wav', '16a01Fc.wav']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(os.path.join(DATA_BASE_PATH, 'working')))\n",
    "print(os.listdir(os.path.join(DATA_BASE_PATH, 'working', 'wav'))[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the task at hand, only the content of the `wav` folder are relevant. It contains wav-files that are named in the following schema (according to the documentation.\n",
    "\n",
    "```\n",
    "Positions 1-2: number of speaker\n",
    "Positions 3-5: code for text\n",
    "Position 6: emotion (sorry, letter stands for german emotion word)\n",
    "Position 7: if there are more than two versions these are numbered a, b, c ....\n",
    "```\n",
    "\n",
    "The documentation further states information about the speakers:\n",
    "\n",
    "```\n",
    "03 - male, 31 years old\n",
    "08 - female, 34 years\n",
    "09 - female, 21 years\n",
    "10 - male, 32 years\n",
    "11 - male, 26 years\n",
    "12 - male, 30 years\n",
    "13 - female, 32 years\n",
    "14 - female, 35 years\n",
    "15 - male, 25 years\n",
    "16 - female, 31 years\n",
    "```\n",
    "\n",
    "And about the spoken sample:\n",
    "\n",
    "|code|text (german)|try of an english translation|\n",
    "|--- |--- |--- |\n",
    "|a01|Der Lappen liegt auf dem Eisschrank.|The tablecloth is lying on the frigde.|\n",
    "|a02|Das will sie am Mittwoch abgeben.|She will hand it in on Wednesday.|\n",
    "|a04|Heute abend könnte ich es ihm sagen.|Tonight I could tell him.|\n",
    "|a05|Das schwarze Stück Papier befindet sich da oben neben dem Holzstück.|The black sheet of paper is located up there besides the piece of timber.|\n",
    "|a07|In sieben Stunden wird es soweit sein.|In seven hours it will be.|\n",
    "|b01|Was sind denn das für Tüten, die da unter dem Tisch stehen?|What about the bags standing there under the table?|\n",
    "|b02|Sie haben es gerade hochgetragen und jetzt gehen sie wieder runter.|They just carried it upstairs and now they are going down again.|\n",
    "|b03|An den Wochenenden bin ich jetzt immer nach Hause gefahren und habe Agnes besucht.|Currently at the weekends I always went home and saw Agnes.|\n",
    "|b09|Ich will das eben wegbringen und dann mit Karl was trinken gehen.|I will just discard this and then go for a drink with Karl.|\n",
    "|b10|Die wird auf dem Platz sein, wo wir sie immer hinlegen.|It will be in the place where we always store it.|\n",
    "\n",
    "And lastly, some information about the emotions:\n",
    "\n",
    "|letter|emotion (english)|letter|emotion (german)|\n",
    "|--- |--- |--- |--- |\n",
    "|A|anger|W|Ärger (Wut)|\n",
    "|B|boredom|L|Langeweile|\n",
    "|D|disgust|E|Ekel|\n",
    "|F|anxiety/fear|A|Angst|\n",
    "|H|happiness|F|Freude|\n",
    "|S|sadness|T|Trauer|\n",
    "\n",
    "Note: `N` is also an option which stands for `Neutral`.\n",
    "\n",
    "So, the sample `16a02Lb.wav` can be parsed as the following:\n",
    "\n",
    "* Speaker = 16 - female, 31 years\n",
    "* Text = a02 for \"Das will sie am Mittwoch abgeben.\"\n",
    "* Emotion = L for \"Langeweile\"\n",
    "* Version = b (i.e., there is at least another version a in the dataset)\n",
    "\n",
    "The dataset function `.prepare()` is meant to create a pandas DataFrame that parses this information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>full_path</th>\n",
       "      <th>speaker</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16a02Lb.wav</td>\n",
       "      <td>/Users/nik/Code/visium/data/working/wav/16a02L...</td>\n",
       "      <td>16</td>\n",
       "      <td>a02</td>\n",
       "      <td>L</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14a07Wc.wav</td>\n",
       "      <td>/Users/nik/Code/visium/data/working/wav/14a07W...</td>\n",
       "      <td>14</td>\n",
       "      <td>a07</td>\n",
       "      <td>W</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10a07Ad.wav</td>\n",
       "      <td>/Users/nik/Code/visium/data/working/wav/10a07A...</td>\n",
       "      <td>10</td>\n",
       "      <td>a07</td>\n",
       "      <td>A</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13a05Ea.wav</td>\n",
       "      <td>/Users/nik/Code/visium/data/working/wav/13a05E...</td>\n",
       "      <td>13</td>\n",
       "      <td>a05</td>\n",
       "      <td>E</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14a05Wa.wav</td>\n",
       "      <td>/Users/nik/Code/visium/data/working/wav/14a05W...</td>\n",
       "      <td>14</td>\n",
       "      <td>a05</td>\n",
       "      <td>W</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      filename                                          full_path speaker  \\\n",
       "0  16a02Lb.wav  /Users/nik/Code/visium/data/working/wav/16a02L...      16   \n",
       "1  14a07Wc.wav  /Users/nik/Code/visium/data/working/wav/14a07W...      14   \n",
       "2  10a07Ad.wav  /Users/nik/Code/visium/data/working/wav/10a07A...      10   \n",
       "3  13a05Ea.wav  /Users/nik/Code/visium/data/working/wav/13a05E...      13   \n",
       "4  14a05Wa.wav  /Users/nik/Code/visium/data/working/wav/14a05W...      14   \n",
       "\n",
       "  text emotion version  \n",
       "0  a02       L       b  \n",
       "1  a07       W       c  \n",
       "2  a07       A       d  \n",
       "3  a05       E       a  \n",
       "4  a05       W       a  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speakers = ['03', '08', '09', '10', '11', '12', '13', '14', '15', '16']\n",
    "texts = ['a01', 'a02', 'a04', 'a05', 'a07', 'b01', 'b02', 'b03', 'b09', 'b10']\n",
    "emotions = {\n",
    "    'W': 'Ärger (Wut)',\n",
    "    'L': 'Langeweile',\n",
    "    'E': 'Ekel',\n",
    "    'A': 'Angst',\n",
    "    'F': 'Freude',\n",
    "    'T': 'Trauer',\n",
    "    'N': 'Neutral'\n",
    "}\n",
    "files = list()\n",
    "for filename in os.listdir(os.path.join(dataset.working_path, 'wav')):\n",
    "    assert len(filename) == 11, 'Encountered unknown filename.'\n",
    "    _speaker = filename[0:2]\n",
    "    assert _speaker in speakers, 'Encountered unknown speaker.'\n",
    "    _text = filename[2:5]\n",
    "    assert _text in texts, 'Encountered unknown text.'\n",
    "    _emotion = filename[5:6]\n",
    "    assert _emotion in emotions.keys(), 'Encountered unknown emotion.'\n",
    "    _version = filename[6:7]\n",
    "    assert _version in list('abcdefghijklmnopqrstuvwxyz'), 'Encountered unknown version.'\n",
    "    files.append({\n",
    "        'filename': filename,\n",
    "        'full_path': os.path.join(dataset.working_path, 'wav', filename),\n",
    "        'speaker': _speaker, \n",
    "        'text': _text,\n",
    "        'emotion': _emotion,\n",
    "        'version': _version\n",
    "    })\n",
    "pd.DataFrame(files).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-22 17:29:59,924 - ser.dataset - WARNING - Apparently, the dataset has not yet been prepareed. Use .prepare() to prepare it first.\n"
     ]
    }
   ],
   "source": [
    "dataset.prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering & Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results & Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
